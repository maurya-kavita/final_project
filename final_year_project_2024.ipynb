{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14279303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\kavita\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from lightgbm) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd058add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\kavita\\anaconda3\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: plotly in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: graphviz in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: six in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2021.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62413be",
   "metadata": {},
   "source": [
    "# Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6c31678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1ce865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\kavita\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from xgboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\kavita\\anaconda3\\lib\\site-packages (from xgboost) (1.7.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b021e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede5e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48a0c22",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470498e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake reviews dataset.csv', names=['category', 'rating', 'label', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beefc707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \n",
       "0                                                                              text_  \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty  \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years  \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.  \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7065e9cc",
   "metadata": {},
   "source": [
    "# Check for data imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "988ff341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CG       20216\n",
       "OR       20216\n",
       "label        1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521f0014",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa81fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57b0861b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = np.where(df['label']=='CG', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ceacb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    20217\n",
       "1    20216\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d572bcd",
   "metadata": {},
   "source": [
    "# Create features from punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe1009df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def punctuation_to_features(df, column):\n",
    "    \"\"\"Identify punctuation within a column and convert to a text representation.\n",
    "    \n",
    "    Args:\n",
    "        df (object): Pandas dataframe.\n",
    "        column (string): Name of column containing text. \n",
    "        \n",
    "    Returns:\n",
    "        df[column]: Original column with punctuation converted to text, \n",
    "                    i.e. \"Wow! > \"Wow exclamation\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df[column] = df[column].replace('!', ' exclamation ')\n",
    "    df[column] = df[column].replace('?', ' question ')\n",
    "    df[column] = df[column].replace('\\'', ' quotation ')\n",
    "    df[column] = df[column].replace('\\\"', ' quotation ')\n",
    "    \n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eb47b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = punctuation_to_features(df, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddd96b8",
   "metadata": {},
   "source": [
    "# Tokenize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19abdd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\KAVITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt');\n",
    "\n",
    "def tokenize(column):\n",
    "    \"\"\"Tokenizes a Pandas dataframe column and returns a list of tokens.\n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column (i.e. df['text']).\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list, i.e. [Donald, Trump, tweets]\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    tokens = nltk.word_tokenize(column)\n",
    "    return [w for w in tokens if w.isalpha()] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7c7091d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \n",
       "0                                                                                                []  \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]  \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]  \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]  \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized'] = df.apply(lambda x: tokenize(x['text']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4dd170",
   "metadata": {},
   "source": [
    "# Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05fa39bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KAVITA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a0cbe920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokenized_column):\n",
    "    \"\"\"Return a list of tokens with English stopwords removed. \n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column of tokenized data from tokenize()\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list with stopwords removed.\n",
    "    \n",
    "    \"\"\"\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return [word for word in tokenized_column if not word in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "740f276a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "0                                                                                                []   \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "\n",
       "                                                stopwords_removed  \n",
       "0                                                              []  \n",
       "1  [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]  \n",
       "2        [love, great, upgrade, original, I, mine, couple, years]  \n",
       "3        [This, pillow, saved, back, I, love, look, feel, pillow]  \n",
       "4           [Missing, information, use, great, product, price, I]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stopwords_removed'] = df.apply(lambda x: remove_stopwords(x['tokenized']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc2411",
   "metadata": {},
   "source": [
    "# Apply Porter stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb6546c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_stemming(tokenized_column):\n",
    "    \"\"\"Return a list of tokens with Porter stemming applied.\n",
    "    \n",
    "    Args:\n",
    "        column: Pandas dataframe column of tokenized data with stopwords removed.\n",
    "    \n",
    "    Returns:\n",
    "        tokens (list): Tokenized list with words Porter stemmed.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    stemmer = PorterStemmer() \n",
    "    return [stemmer.stem(word).lower() for word in tokenized_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0c83198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>porter_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>category</td>\n",
       "      <td>rating</td>\n",
       "      <td>label</td>\n",
       "      <td>text_</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty</td>\n",
       "      <td>1</td>\n",
       "      <td>[Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]</td>\n",
       "      <td>[Love, Well, made, sturdy, comfortable, I, love, Very, pretty]</td>\n",
       "      <td>[love, well, made, sturdi, comfort, i, love, veri, pretti]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>love it, a great upgrade from the original.  I've had mine for a couple of years</td>\n",
       "      <td>1</td>\n",
       "      <td>[love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]</td>\n",
       "      <td>[love, great, upgrade, original, I, mine, couple, years]</td>\n",
       "      <td>[love, great, upgrad, origin, i, mine, coupl, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>This pillow saved my back. I love the look and feel of this pillow.</td>\n",
       "      <td>1</td>\n",
       "      <td>[This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]</td>\n",
       "      <td>[This, pillow, saved, back, I, love, look, feel, pillow]</td>\n",
       "      <td>[thi, pillow, save, back, i, love, look, feel, pillow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Home_and_Kitchen_5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CG</td>\n",
       "      <td>Missing information on how to use it, but it is a great product for the price!  I</td>\n",
       "      <td>1</td>\n",
       "      <td>[Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]</td>\n",
       "      <td>[Missing, information, use, great, product, price, I]</td>\n",
       "      <td>[miss, inform, use, great, product, price, i]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category  rating  label  \\\n",
       "0            category  rating  label   \n",
       "1  Home_and_Kitchen_5     5.0     CG   \n",
       "2  Home_and_Kitchen_5     5.0     CG   \n",
       "3  Home_and_Kitchen_5     5.0     CG   \n",
       "4  Home_and_Kitchen_5     1.0     CG   \n",
       "\n",
       "                                                                                text  \\\n",
       "0                                                                              text_   \n",
       "1        Love this!  Well made, sturdy, and very comfortable.  I love it!Very pretty   \n",
       "2   love it, a great upgrade from the original.  I've had mine for a couple of years   \n",
       "3                This pillow saved my back. I love the look and feel of this pillow.   \n",
       "4  Missing information on how to use it, but it is a great product for the price!  I   \n",
       "\n",
       "   target  \\\n",
       "0       0   \n",
       "1       1   \n",
       "2       1   \n",
       "3       1   \n",
       "4       1   \n",
       "\n",
       "                                                                                          tokenized  \\\n",
       "0                                                                                                []   \n",
       "1               [Love, this, Well, made, sturdy, and, very, comfortable, I, love, it, Very, pretty]   \n",
       "2       [love, it, a, great, upgrade, from, the, original, I, had, mine, for, a, couple, of, years]   \n",
       "3                  [This, pillow, saved, my, back, I, love, the, look, and, feel, of, this, pillow]   \n",
       "4  [Missing, information, on, how, to, use, it, but, it, is, a, great, product, for, the, price, I]   \n",
       "\n",
       "                                                stopwords_removed  \\\n",
       "0                                                              []   \n",
       "1  [Love, Well, made, sturdy, comfortable, I, love, Very, pretty]   \n",
       "2        [love, great, upgrade, original, I, mine, couple, years]   \n",
       "3        [This, pillow, saved, back, I, love, look, feel, pillow]   \n",
       "4           [Missing, information, use, great, product, price, I]   \n",
       "\n",
       "                                               porter_stemmed  \n",
       "0                                                          []  \n",
       "1  [love, well, made, sturdi, comfort, i, love, veri, pretti]  \n",
       "2         [love, great, upgrad, origin, i, mine, coupl, year]  \n",
       "3      [thi, pillow, save, back, i, love, look, feel, pillow]  \n",
       "4               [miss, inform, use, great, product, price, i]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['porter_stemmed'] = df.apply(lambda x: apply_stemming(x['stopwords_removed']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996e14ec",
   "metadata": {},
   "source": [
    "# Rejoin words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d75d7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rejoin_words(tokenized_column):\n",
    "    return ( \" \".join(tokenized_column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b256eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['all_text'] = df.apply(lambda x: rejoin_words(x['porter_stemmed']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb9ad684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>love well made sturdi comfort i love veri pretti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love great upgrad origin i mine coupl year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thi pillow save back i love look feel pillow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miss inform use great product price i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           all_text\n",
       "0                                                  \n",
       "1  love well made sturdi comfort i love veri pretti\n",
       "2        love great upgrad origin i mine coupl year\n",
       "3      thi pillow save back i love look feel pillow\n",
       "4             miss inform use great product price i"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['all_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a03f5ef",
   "metadata": {},
   "source": [
    "# Create training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eec9a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['all_text']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4be3897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8583c238",
   "metadata": {},
   "source": [
    "# Run the model selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42ae3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {}\n",
    "classifiers.update({\"XGBClassifier\": XGBClassifier(eval_metric='logloss',\n",
    "                                                   objective='binary:logistic',\n",
    "                                                   )})\n",
    "classifiers.update({\"CatBoostClassifier\": CatBoostClassifier(silent=True)})\n",
    "classifiers.update({\"LinearSVC\": LinearSVC()})\n",
    "classifiers.update({\"MultinomialNB\": MultinomialNB()})\n",
    "classifiers.update({\"LGBMClassifier\": LGBMClassifier()})\n",
    "classifiers.update({\"RandomForestClassifier\": RandomForestClassifier()})\n",
    "classifiers.update({\"DecisionTreeClassifier\": DecisionTreeClassifier()})\n",
    "classifiers.update({\"ExtraTreeClassifier\": ExtraTreeClassifier()})\n",
    "classifiers.update({\"AdaBoostClassifier\": AdaBoostClassifier()})\n",
    "classifiers.update({\"KNeighborsClassifier\": KNeighborsClassifier()})\n",
    "classifiers.update({\"RidgeClassifier\": RidgeClassifier()})\n",
    "classifiers.update({\"SGDClassifier\": SGDClassifier()})\n",
    "classifiers.update({\"BaggingClassifier\": BaggingClassifier()})\n",
    "classifiers.update({\"BernoulliNB\": BernoulliNB()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c2a45f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 16173, number of negative: 16173\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.250084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 176207\n",
      "[LightGBM] [Info] Number of data points in the train set: 32346, number of used features: 3262\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 16173, number of negative: 16173\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 171382\n",
      "[LightGBM] [Info] Number of data points in the train set: 32346, number of used features: 3141\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Number of positive: 16172, number of negative: 16174\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.213499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 175640\n",
      "[LightGBM] [Info] Number of data points in the train set: 32346, number of used features: 3259\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499969 -> initscore=-0.000124\n",
      "[LightGBM] [Info] Start training from score -0.000124\n",
      "[LightGBM] [Info] Number of positive: 16173, number of negative: 16174\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.240889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 169835\n",
      "[LightGBM] [Info] Number of data points in the train set: 32347, number of used features: 3109\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499985 -> initscore=-0.000062\n",
      "[LightGBM] [Info] Start training from score -0.000062\n",
      "[LightGBM] [Info] Number of positive: 16173, number of negative: 16174\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227992 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 174248\n",
      "[LightGBM] [Info] Number of data points in the train set: 32347, number of used features: 3260\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499985 -> initscore=-0.000062\n",
      "[LightGBM] [Info] Start training from score -0.000062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n",
      "C:\\Users\\KAVITA\\AppData\\Local\\Temp\\ipykernel_23256\\2943509803.py:15: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_models = df_models.append(row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.DataFrame(columns=['model', 'run_time', 'roc_auc', 'roc_auc_std'])\n",
    "\n",
    "for key in classifiers:\n",
    "    \n",
    "    start_time = time.time()\n",
    "    pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), (\"clf\", classifiers[key] )])\n",
    "    cv = cross_val_score(pipeline, X, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "    row = {'model': key,\n",
    "           'run_time': format(round((time.time() - start_time)/60,2)),\n",
    "           'roc_auc': cv.mean(),\n",
    "           'roc_auc_std': cv.std(),\n",
    "    }\n",
    "    \n",
    "    df_models = df_models.append(row, ignore_index=True)\n",
    "    \n",
    "df_models = df_models.sort_values(by='roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff12031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>run_time</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>roc_auc_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.925487</td>\n",
       "      <td>0.008782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoostClassifier</td>\n",
       "      <td>37.34</td>\n",
       "      <td>0.922597</td>\n",
       "      <td>0.009725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.922388</td>\n",
       "      <td>0.01261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.922283</td>\n",
       "      <td>0.013242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.917487</td>\n",
       "      <td>0.010876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.916505</td>\n",
       "      <td>0.010626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>8.17</td>\n",
       "      <td>0.91157</td>\n",
       "      <td>0.013524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.901796</td>\n",
       "      <td>0.019819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>11.37</td>\n",
       "      <td>0.857332</td>\n",
       "      <td>0.009445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.844253</td>\n",
       "      <td>0.020967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.82851</td>\n",
       "      <td>0.020334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.736147</td>\n",
       "      <td>0.011979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.704106</td>\n",
       "      <td>0.035001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreeClassifier</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.657458</td>\n",
       "      <td>0.021071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model run_time   roc_auc roc_auc_std\n",
       "11           SGDClassifier     0.11  0.925487    0.008782\n",
       "1       CatBoostClassifier    37.34  0.922597    0.009725\n",
       "2                LinearSVC     0.12  0.922388     0.01261\n",
       "10         RidgeClassifier     0.12  0.922283    0.013242\n",
       "4           LGBMClassifier     0.65  0.917487    0.010876\n",
       "0            XGBClassifier      2.4  0.916505    0.010626\n",
       "5   RandomForestClassifier     8.17   0.91157    0.013524\n",
       "3            MultinomialNB      0.1  0.901796    0.019819\n",
       "12       BaggingClassifier    11.37  0.857332    0.009445\n",
       "8       AdaBoostClassifier     0.63  0.844253    0.020967\n",
       "13             BernoulliNB      0.1   0.82851    0.020334\n",
       "6   DecisionTreeClassifier     1.96  0.736147    0.011979\n",
       "9     KNeighborsClassifier     0.92  0.704106    0.035001\n",
       "7      ExtraTreeClassifier     0.18  0.657458    0.021071"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa36d105",
   "metadata": {},
   "source": [
    "# Assess the selected model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bdbdd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundled_pipeline = Pipeline([(\"tfidf\", TfidfVectorizer()), \n",
    "                             (\"clf\", SGDClassifier())\n",
    "                            ])\n",
    "bundled_pipeline.fit(X_train, y_train)\n",
    "y_pred = bundled_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "24ded0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score = accuracy_score(y_test, y_pred)\n",
    "precision_score = precision_score(y_test, y_pred)\n",
    "recall_score = recall_score(y_test, y_pred)\n",
    "roc_auc_score = roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1a279a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8695795548227535\n",
      "Precision: 0.8928755364806867\n",
      "Recall: 0.8444552687124534\n",
      "ROC/AUC: 0.8699750803451731\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score)\n",
    "print('Precision:', precision_score)\n",
    "print('Recall:', recall_score)\n",
    "print('ROC/AUC:', roc_auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
